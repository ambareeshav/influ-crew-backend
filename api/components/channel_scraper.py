from apify_client import ApifyClient
from datetime import datetime
from typing import Dict, Any 
from tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type
import os, logging, gc

KEY = os.getenv("APIFY_API_KEY")
client = ApifyClient(KEY)

# Import custom modules
import api.components.summarizer as summarizer

# Configure logging
logging.basicConfig(level=logging.ERROR)  
logger = logging.getLogger(__name__)

def video_det_store(run: Dict[str, Any], channel_info: Dict[str, Any]) -> None:  
    # Iterate through videos in the dataset
    for video in client.dataset(run["defaultDatasetId"]).iterate_items():
       
        channelId = video.get('channelUrl').split("/")[-1]
        
        # If channel not in channel_info, add it to the dict
        if channelId not in channel_info:
            # Initialize channel information
            channel_info[channelId] = {
                'channel_name': video.get('channelName'),
                'channel_description_links': video.get('channelDescriptionLinks'),
                'subscriber_count': video.get('numberOfSubscribers'),
                'video_dates': [],
                'videos': []
            }
        
        # Add video date to the video_dates list
        video_date = datetime.fromisoformat(video.get('date')).date()
        channel_info[channelId]['video_dates'].append(str(video_date))
        
        # Get video transcript and summary
        transcript = summarizer.transcript(video.get('id'))
        if transcript:
            try:
                summarized_transcript = summarizer.summarize_text(transcript)
            except Exception as e:
                logging.error(f"ERROR during summarization - {e}")


        # Add video details to the channel's videos list
        channel_info[channelId]['videos'].append({
            'date': str(video_date),
            'title': video.get('title'),
            'viewCount': video.get('viewCount'),
            'likeCount': video.get('likes'),
            'commentsCount': video.get('commentsCount'),
            'full_transcript': transcript,
            'transcript_report': summarized_transcript,
            'duration': video.get('duration'),
            'description': video.get('text'),
            'description_links': video.get('descriptionLinks')
        })
        
        # Manually trigger garbage collection after processing each video to free up memory
        gc.collect()
@retry(wait=wait_exponential(min=1, max=10), stop=stop_after_attempt(5), retry=retry_if_exception_type(Exception))
def get_video_det(channel_info: Dict[str, Any], link: str) -> Dict[str, Any]:
    # Define input parameters for YouTube scraper
    input = {
        "downloadSubtitles": False,
        "hasCC": False,
        "hasLocation": False,
        "hasSubtitles": False,
        "is360": False,
        "is3D": False,
        "is4K": False,
        "isBought": False,
        "isHD": False,
        "isHDR": False,
        "isLive": False,
        "isVR180": False,
        "lengthFilter": "between420",
        "maxResultStreams": 0,
        "maxResults": 5,
        "maxResultsShorts": 0,
        "preferAutoGeneratedSubtitles": False,
        "saveSubsToKVS": False,
        "startUrls": [{"url": link}],
        "subtitlesLanguage": "any",
        "subtitlesFormat": "srt"
    }

    # Run scraper
    run = client.actor("streamers/youtube-scraper").call(run_input=input)

    # Store details of current video in iteration
    video_det_store(run, channel_info)
    return channel_info

def cscraper(link: str) -> Dict[str, Any]:
    # Initialize channel_info dict
    channel_info = {}

    # Get video details for the given link
    channel_info = get_video_det(channel_info, link)

    # Final garbage collection after the entire operation
    gc.collect()

    return channel_info
